---
title: 'Stat 579 - Homework #8 - Section A'
date: "10/24/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Urban stream monitoring

For this homework, we will be using the Ames City Urban stream monitoring project available at https://www.cityofames.org/government/departments-divisions-i-z/water-pollution-control/urban-stream-monitoring

1. Download the RMarkdown file with these homework instructions to use as a template for your work.
Make sure to replace "Your Name" in the YAML with your name.
2. Read the information available on the Urban Stream Monitoring project https://www.cityofames.org/government/departments-divisions-i-z/water-pollution-control/urban-stream-monitoring

The table presented on this website can be read into R using the following couple of commands.

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(rvest)
url <- "https://www.cityofames.org/government/departments-divisions-i-z/water-pollution-control/urban-stream-monitoring"
doc <- read_html(url)
tables <- doc %>% html_table(fill=TRUE)
ames <- data.frame(tables[[1]])
head(ames)
ames<-ames[1:76,] #remove last empty row in dataset
```
The overarching goal of this homework is to clean the data and get it into a format ready for an analysis.

3. Bring the data into long form. 
```{r}
ames_long<-ames %>% pivot_longer(names_to = "location",values_to= "cfu", Skunk.River:Worle.Creek)
```

4. Measurements of E.Coli are in character format. Convert these values properly into numbers. How many missing values are there? What is the average of the measurements?
There are 33 missing values of E. coli levels The average of the measurements of CFU is 2808.697 colony forming units in a 100 mL sample.
```{r}
ames_long<-ames_long %>% mutate(cfu=parse_number(cfu))

ames_long %>% filter(is.na(cfu)) %>% count()

ames_long %>% filter(!is.na(cfu)) %>% summarize(mean_cfu=mean(cfu))
```

5. The `Sample.Date` variable is a mess. Use `separate` to get the information into Month, Day and Year. Make sure that the `Sample.Date` variable is not being removed from the data in this process.
```{r}
ames_long<-ames_long %>% separate("Sample.Date", sep=" ", remove=FALSE, into=c("Month","Day","Year")) %>%
  mutate("Day"=parse_number(Day),
         "Year"=parse_number(Year),
         "Month"=factor(Month, levels = month.name, labels = month.abb))
```

6. Plot measurements by month, colour by creek, and facet by year. Describe the plot in 2-3 sentences.  
```{r}
ames_long %>% ggplot(aes(x=Month, y=cfu, fill=location)) + geom_bar(stat="identity") + 
  facet_wrap(~Year) + theme_bw() + ylab("CFU of E. coli") + xlab("Month") + theme(axis.text.x = element_text(angle = 90))
```
From these plots, it is clear to see that some years had elevated levels of E. coli compared to others, particularly in 2009, 2012 and 2018 while 2014, 2013, 2017 and 2016 had reletively lower levels. Over the course of these 10 years, there are 4 noticeable months that had much higher levels of E. coli which were May of 2009, July of 2011, September of 2012, and June of 2018. From the barcharts, it appears that Worle Creek and College Creek were the places with the highest levels of E. coli reported during any one single month.

7. Introduce a variable `Type` into the dataset that is `fecal coliform bacteria` for measurements before August 14, 2018 and `E.coli` for measurements taken afterwards.
```{r}
ames_long %>% mutate(Type=ifelse((Month %in% c("Sep","Oct","Nov","Dec") & Year==2018)|(Month=="Aug"&Day>=14&Year==2018)|Year>2018,"E.coli","fecal coliform bacteria"))
```
8. `lubridate` is an R package for working with times and dates. Use [RStudio's cheatsheet for lubridate](https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf) to find a way to convert the variable `Sample.Date` to a date.
```{r}
library(lubridate)
ames_long %>% mutate(Date=mdy(Sample.Date))
```


Due date: please refer to the website and Canvas for the due date. 

For the submission: submit your solution in an R Markdown file and (just for insurance) submit the corresponding html/word file with it. 
